# DocQA-MS ‚Äî Assistant M√©dical sur Documents Cliniques

![Architecture](https://img.shields.io/badge/Architecture-Microservices-blue)
![Java](https://img.shields.io/badge/Java-17+-orange)
![Python](https://img.shields.io/badge/Python-3.11+-green)
![React](https://img.shields.io/badge/React-18-61DAFB)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED)

## üìã Derni√®res Modifications (6 D√©cembre 2025)

### ‚ú® Nouvelles Fonctionnalit√©s
- **Synth√®se Intelligente fonctionnelle** : Affichage correct des r√©sum√©s g√©n√©r√©s par IA avec structure r√©sum√© + points cl√©s
- **Migration vers Llama 3.1 8B** : Remplacement de Mistral Nemo 12B (7.1GB) par Llama 3.1 8B (4.9GB) pour une meilleure efficacit√© m√©moire

### üêõ Corrections
- Correction du bug d'affichage des synth√®ses dans le frontend
- R√©solution du probl√®me de transformation des donn√©es API entre backend et frontend
- Am√©lioration de la gestion du cache Docker lors des rebuilds

### üîß Am√©liorations Techniques
- Ajout de logs de d√©bogage pour le suivi du flux de g√©n√©ration de synth√®ses
- Optimisation de la configuration Docker pour forcer les rebuilds sans cache
- Mise √† jour de la documentation avec les nouveaux param√®tres du mod√®le

## üè• Contexte

Syst√®me intelligent de traitement et analyse de documents m√©dicaux non structur√©s utilisant des LLM (Large Language Models) pour transformer les textes cliniques en r√©ponses pr√©cises et contextualis√©es.

## üéØ Objectifs

- ‚úÖ R√©pondre √† des questions en langage naturel √† partir des documents internes
- ‚úÖ Extraire des informations pr√©cises : maladies, traitements, ant√©c√©dents
- ‚úÖ Fournir des r√©sum√©s ou comparaisons entre patients
- ‚úÖ Garantir confidentialit√©, anonymisation et tra√ßabilit√© des donn√©es

## Architecture Microservices

```
+---------------------------------------------------------------------------+
|                        INTERFACE CLINIQUE (React)                         |
|                              Port: 3000                                   |
+---------------------------------------------------------------------------+
                                     |
                                     v
+---------------------------------------------------------------------------+
|                          API GATEWAY (Python)                              |
|                              Port: 8000                                    |
|              Point d'entree unique pour tous les microservices             |
+---------------------------------------------------------------------------+
                                     |
        +----------------------------+----------------------------+
        |              |             |              |             |
        v              v             v              v             v
+-------------+ +-------------+ +-------------+ +-------------+ +-------------+
|Doc Ingestor | |DeID Service | |  Indexeur   | | LLM QA      | |  Synthese   |
|  (Python)   | |   (Java)    | | Semantique  | |   Module    | | Comparative |
| Port: 8001  | | Port: 8002  | | Port: 8003  | | Port: 8004  | | Port: 8005  |
+-------------+ +-------------+ +-------------+ +-------------+ +-------------+
        |              |             |              |             |
        +-------+------+------+------+------+------+------+------+
                |             |             |             |
                v             v             v             v
        +-------------+ +-------------+ +-------------+
        |   RabbitMQ  | | PostgreSQL  | |Audit Logger |
        |  Port: 5672 | |  Port: 5433 | | Port: 8006  |
        +-------------+ +-------------+ +-------------+

FLUX DE MESSAGES (RabbitMQ):
  Doc Ingestor --> [documents.raw] --> DeID Service
  DeID Service --> [documents.deid] --> Indexeur Semantique
  Indexeur Semantique --> [documents.indexed]
  All Services --> [audit.events] --> Audit Logger
```

### Microservices

| Service                  | Port | Langage          | Description                            |
| ------------------------ | ---- | ---------------- | -------------------------------------- |
| **API Gateway**          | 8000 | Python/FastAPI   | Point d'entree unique, proxy           |
| **Doc Ingestor**         | 8001 | Python/FastAPI   | Ingestion OCR, extraction de texte     |
| **DeID Service**         | 8002 | Java/Spring Boot | Anonymisation des donnees personnelles |
| **Indexeur Semantique**  | 8003 | Java/Spring Boot | Vectorisation et recherche semantique  |
| **LLM QA Module**        | 8004 | Python/FastAPI   | Questions/Reponses avec LLM            |
| **Synthese Comparative** | 8005 | Java/Spring Boot | Generation de resumes                  |
| **Audit Logger**         | 8006 | Java/Spring Boot | Tracabilite et audit                   |
| **Interface Clinique**   | 3000 | React            | Interface utilisateur                  |

## üöÄ D√©marrage Rapide

### Pr√©requis

- Docker & Docker Compose
- (Optionnel) Ollama pour LLM local

### 1. Cloner le projet

```bash
git clone <repository-url>
cd DocQA-MS
```

### 2. D√©marrer l'infrastructure

```bash
# Infrastructure seule (PostgreSQL + RabbitMQ)
docker-compose up -d postgres rabbitmq

# V√©rifier le statut
docker-compose ps
```

### 3. D√©marrer tous les services

```bash
# Tous les microservices
docker-compose up -d

# Suivre les logs
docker-compose logs -f
```

### 4. Acc√©der aux interfaces

| Interface               | URL                    |
| ----------------------- | ---------------------- |
| **Application**         | http://localhost:3000  |
| **RabbitMQ Management** | http://localhost:15672 |
| **pgAdmin** (optionnel) | http://localhost:5050  |

## üìÅ Structure du Projet

```
DocQA-MS/
‚îú‚îÄ‚îÄ docker-compose.yml              # Orchestration Docker
‚îú‚îÄ‚îÄ README.md                       # Documentation
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ application.properties      # Configuration partag√©e
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îî‚îÄ‚îÄ init-scripts/              # Scripts d'initialisation DB
‚îî‚îÄ‚îÄ microservices/
    ‚îú‚îÄ‚îÄ doc-ingestor/              # Python/FastAPI
    ‚îú‚îÄ‚îÄ deid-service/              # Java/Spring Boot
    ‚îú‚îÄ‚îÄ indexeur-semantique/       # Java/Spring Boot
    ‚îú‚îÄ‚îÄ llm-qa-module/             # Python/FastAPI
    ‚îú‚îÄ‚îÄ synthese-comparative/      # Java/Spring Boot
    ‚îú‚îÄ‚îÄ audit-logger/              # Java/Spring Boot
    ‚îî‚îÄ‚îÄ interface-clinique/        # React/Tailwind
```

## üîß Configuration

### Variables d'environnement principales

| Variable          | Description     | D√©faut                                                         |
| ----------------- | --------------- | -------------------------------------------------------------- |
| `DATABASE_URL`    | URL PostgreSQL  | `postgresql://docqa_user:docqa_password@postgres:5432/docqa_*` |
| `RABBITMQ_HOST`   | H√¥te RabbitMQ   | `rabbitmq`                                                     |
| `LLM_PROVIDER`    | Fournisseur LLM | `ollama`                                                       |
| `OLLAMA_BASE_URL` | URL Ollama      | `http://host.docker.internal:11434`                            |

### Configuration LLM - Llama 3.1 8B avec RAG

Le syst√®me utilise **Llama 3.1 8B** via Ollama avec une architecture RAG (Retrieval-Augmented Generation) pour des r√©ponses pr√©cises bas√©es sur les documents m√©dicaux. Ce mod√®le a √©t√© choisi pour son efficacit√© m√©moire (4.9GB) tout en maintenant d'excellentes performances.

#### Pr√©requis: Installer Ollama et Llama 3.1

**Windows:**

```powershell
# T√©l√©charger et installer Ollama depuis https://ollama.com/download
# Ou via winget:
winget install Ollama.Ollama

# T√©l√©charger le mod√®le Llama 3.1 8B (environ 4.9 Go)
ollama pull llama3.1

# D√©marrer le serveur Ollama
ollama serve
```

**Linux/Mac:**

```bash
# Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# T√©l√©charger Llama 3.1 8B
ollama pull llama3.1

# D√©marrer le serveur
ollama serve
```

#### V√©rifier l'installation

```bash
# V√©rifier que Ollama fonctionne
curl http://localhost:11434/api/tags

# Tester Llama 3.1
ollama run llama3.1 "Bonjour, es-tu pr√™t?"
```

#### Configuration RAG

Le module LLM QA utilise RAG avec les param√®tres suivants (modifiables via `.env`):

| Param√®tre           | Valeur      | Description                             |
| ------------------- | ----------- | --------------------------------------- |
| `OLLAMA_MODEL`      | `llama3.1`  | Mod√®le Llama 3.1 8B (4.9GB)             |
| `LLM_TEMPERATURE`   | `0.1`       | R√©ponses factuelles (basse temp√©rature) |
| `LLM_NUM_CTX`       | `8192`      | Fen√™tre de contexte                     |
| `RAG_TOP_K_RESULTS` | `5`         | Documents r√©cup√©r√©s                     |
| `USE_RERANKING`     | `true`      | Reranking pour meilleure pr√©cision      |
| `RERANK_TOP_K`      | `3`         | Documents finaux apr√®s reranking        |

**Note:** Llama 3.1 8B offre un excellent √©quilibre entre performance et consommation m√©moire, le rendant id√©al pour des environnements avec des ressources limit√©es.

#### Alternative: OpenAI (Optionnel)

```env
USE_LOCAL_LLM=false
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-3.5-turbo
```

## üß™ Tests

### Ex√©cuter les tests unitaires

```bash
# Java services
cd microservices/deid-service
./mvnw test

# Python services
cd microservices/llm-qa-module
pytest
```

### Health Checks

```bash
# V√©rifier tous les services
curl http://localhost:8001/health
curl http://localhost:8002/actuator/health
curl http://localhost:8003/actuator/health
curl http://localhost:8004/health
curl http://localhost:8005/actuator/health
curl http://localhost:8006/actuator/health
```

## üìä Fonctionnalit√©s

### 1. Ingestion de Documents

- Upload PDF, DOC, DOCX, TXT
- OCR pour documents scann√©s
- Extraction de m√©tadonn√©es

### 2. Anonymisation (DeID)

- D√©tection des noms, pr√©noms
- Anonymisation des dates
- Masquage des num√©ros de s√©curit√© sociale
- Correspondance bidirectionnelle s√©curis√©e

### 3. Recherche S√©mantique

- Embeddings vectoriels
- Recherche par similarit√©
- Filtrage par patient/date

### 4. Questions/R√©ponses

- Interface conversationnelle avec Llama 3.1 8B
- RAG (Retrieval-Augmented Generation) pour r√©ponses pr√©cises
- Contexte patient et historique de conversation
- Sources cit√©es avec num√©ros de documents
- Score de confiance
- Support multilingue (fran√ßais par d√©faut)

### 5. Synth√®ses Intelligentes ‚ú®

- **R√©sum√© automatique** de dossiers patients via IA
- **G√©n√©ration de points cl√©s** extraits des documents
- **Comparaison multi-patients** pour analyses comparatives
- Support de multiples documents simultan√©ment
- Affichage structur√© avec r√©sum√© et points importants
- Export Markdown pour archivage
- G√©n√©ration rapide (8-15 secondes avec Llama 3.1)

### 6. Audit

- Tra√ßabilit√© compl√®te de toutes les op√©rations
- Journalisation des g√©n√©rations de synth√®ses
- Filtrage avanc√© par type d'action et date
- Export CSV pour analyses

## üîí S√©curit√©

- Anonymisation conforme RGPD
- Audit trail complet
- Authentification (√† impl√©menter)
- Chiffrement des donn√©es sensibles

## üìù Licence

Projet de fin d'√©tudes - 2024

## üë• Contributeurs

- D√©veloppeur Principal: [ACHRAF]

### 7. InterfaceClinique (React)

**Port:** 3000  
**R√¥le:** Interface utilisateur web  
**Technologies:** React, Tailwind CSS, Auth0, Chart.js

## üîÑ Workflow

```
DocIngestor ‚Üí DeID ‚Üí IndexeurS√©mantique ‚Üí LLMQAModule ‚Üí SyntheseComparative
                                              ‚Üì
                                        AuditLogger
                                              ‚Üë
                                      InterfaceClinique
```

## üìã Pr√©requis

- Java JDK 17+
- Python 3.10+
- Node.js 16+
- PostgreSQL 18
- RabbitMQ 3.12+
- Maven 3.8+

## üöÄ D√©marrage

### 1. Configuration des bases de donn√©es

```bash
# Voir database/init-scripts/
psql -U postgres -f database/init-scripts/create-databases.sql
```

### 2. D√©marrage de RabbitMQ

```bash
# Voir docs/rabbitmq-setup.md
```

### 3. D√©marrage des microservices

```bash
# DocIngestor
cd microservices/doc-ingestor
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python app.py

# DeID
cd microservices/deid-service
mvn clean install
mvn spring-boot:run

# ... autres services
```

## üìö Documentation

- [Architecture d√©taill√©e](docs/architecture.md)
- [Guide de d√©veloppement](docs/development-guide.md)
- [API Documentation](docs/api-documentation.md)
- [Guide de d√©ploiement](docs/deployment-guide.md)

## üîí S√©curit√©

- Anonymisation automatique des donn√©es personnelles (PII)
- Tra√ßabilit√© compl√®te des acc√®s et requ√™tes
- Authentification et autorisation (Auth0)
- Conformit√© RGPD et r√©glementations m√©dicales

## üë• √âquipe

Projet acad√©mique professionnel - Maroc

## üìÑ License

Academic Use Only
