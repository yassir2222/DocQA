"""
Repository pour l'acc√®s √† la base de donn√©es PostgreSQL
"""
import psycopg2
from psycopg2.extras import RealDictCursor
import json
import logging
from typing import Optional, List, Dict, Any
from datetime import datetime

from config import settings

logger = logging.getLogger(__name__)

# Connexion globale (pool de connexions en production)
_connection = None


def get_connection():
    """Obtient une connexion √† la base de donn√©es"""
    global _connection
    
    if _connection is None or _connection.closed:
        try:
            _connection = psycopg2.connect(
                host=settings.DB_HOST,
                port=settings.DB_PORT,
                database=settings.DB_NAME,
                user=settings.DB_USER,
                password=settings.DB_PASSWORD
            )
            logger.info("‚úÖ Connexion PostgreSQL √©tablie")
        except Exception as e:
            logger.error(f"‚ùå Erreur connexion PostgreSQL: {str(e)}")
            raise
    
    return _connection


def init_database():
    """Initialise la base de donn√©es et cr√©e les tables si n√©cessaire"""
    try:
        conn = get_connection()
        cursor = conn.cursor()
        
        # V√©rifier si la table existe
        cursor.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'documents'
            )
        """)
        
        table_exists = cursor.fetchone()[0]
        
        if table_exists:
            logger.info("‚úÖ Table 'documents' existe d√©j√†")
        else:
            logger.info("‚ö†Ô∏è Table 'documents' n'existe pas, cr√©ation...")
            # Note: La table devrait √™tre cr√©√©e par le script SQL init
            logger.warning("Ex√©cutez le script database/init-scripts/create-databases.sql")
        
        cursor.close()
        
    except Exception as e:
        logger.error(f"‚ùå Erreur initialisation base de donn√©es: {str(e)}")
        raise


def save_document(
    filename: str,
    file_type: str,
    file_size: int,
    text_content: str,
    metadata: Dict[str, Any],
    patient_id: Optional[str] = None,
    document_type: Optional[str] = None
) -> int:
    """
    Sauvegarde un document dans la base de donn√©es
    
    Args:
        filename: Nom du fichier
        file_type: Type/extension du fichier
        file_size: Taille en bytes
        text_content: Contenu textuel extrait
        metadata: M√©tadonn√©es JSON
        patient_id: ID du patient
        document_type: Type de document m√©dical
    
    Returns:
        ID du document cr√©√©
    """
    conn = None
    try:
        conn = get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO documents (
                filename, file_type, file_size, text_content, 
                metadata, patient_id, document_type, processed,
                created_at, updated_at
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
            ) RETURNING id
        """, (
            filename,
            file_type,
            file_size,
            text_content,
            json.dumps(metadata),
            patient_id,
            document_type,
            False,
            datetime.now(),
            datetime.now()
        ))
        
        document_id = cursor.fetchone()[0]
        conn.commit()
        cursor.close()
        
        logger.info(f"‚úÖ Document {document_id} sauvegard√©")
        return document_id
        
    except Exception as e:
        logger.error(f"‚ùå Erreur sauvegarde document: {str(e)}")
        if conn:
            conn.rollback()
        raise


def get_document_by_id(document_id: int) -> Optional[Dict[str, Any]]:
    """
    R√©cup√®re un document par son ID
    
    Args:
        document_id: ID du document
    
    Returns:
        Dictionnaire repr√©sentant le document ou None
    """
    try:
        conn = get_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        cursor.execute("""
            SELECT id, filename, file_type, file_size, 
                   text_content, metadata, patient_id, 
                   document_type, processed, upload_date,
                   created_at, updated_at
            FROM documents
            WHERE id = %s
        """, (document_id,))
        
        row = cursor.fetchone()
        cursor.close()
        
        if row:
            document = dict(row)
            # Convertir les dates en ISO format
            for date_field in ['upload_date', 'created_at', 'updated_at']:
                if document.get(date_field):
                    document[date_field] = document[date_field].isoformat()
            return document
        
        return None
        
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration document {document_id}: {str(e)}")
        raise


def get_all_documents(
    limit: int = 100,
    offset: int = 0,
    patient_id: Optional[str] = None,
    document_type: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    R√©cup√®re tous les documents avec filtres optionnels
    
    Args:
        limit: Nombre maximum de r√©sultats
        offset: Offset pour pagination
        patient_id: Filtrer par patient_id
        document_type: Filtrer par type de document
    
    Returns:
        Liste de documents
    """
    try:
        conn = get_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # Construire la requ√™te avec filtres
        query = """
            SELECT id, filename, file_type, file_size,
                   patient_id, document_type, processed,
                   upload_date, created_at
            FROM documents
            WHERE 1=1
        """
        params = []
        
        if patient_id:
            query += " AND patient_id = %s"
            params.append(patient_id)
        
        if document_type:
            query += " AND document_type = %s"
            params.append(document_type)
        
        query += " ORDER BY created_at DESC LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        cursor.close()
        
        documents = []
        for row in rows:
            doc = dict(row)
            # Convertir les dates
            for date_field in ['upload_date', 'created_at']:
                if doc.get(date_field):
                    doc[date_field] = doc[date_field].isoformat()
            documents.append(doc)
        
        return documents
        
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration documents: {str(e)}")
        raise


def update_document_status(document_id: int, processed: bool):
    """
    Met √† jour le statut de traitement d'un document
    
    Args:
        document_id: ID du document
        processed: Nouveau statut
    """
    conn = None
    try:
        conn = get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            UPDATE documents
            SET processed = %s, updated_at = %s
            WHERE id = %s
        """, (processed, datetime.now(), document_id))
        
        conn.commit()
        cursor.close()
        
        logger.info(f"‚úÖ Document {document_id} mis √† jour (processed={processed})")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur mise √† jour document {document_id}: {str(e)}")
        if conn:
            conn.rollback()
        raise


def close_connection():
    """Ferme la connexion √† la base de donn√©es"""
    global _connection
    if _connection and not _connection.closed:
        _connection.close()
        logger.info("üîå Connexion PostgreSQL ferm√©e")
