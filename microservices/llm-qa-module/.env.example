# LLMQAModule - Configuration
# Copier ce fichier vers .env et ajuster les valeurs

# ===========================================
# SERVICE CONFIGURATION
# ===========================================
SERVICE_NAME=LLMQAModule
SERVICE_PORT=8004
SERVICE_HOST=0.0.0.0
DEBUG=True

# ===========================================
# DATABASE CONFIGURATION
# ===========================================
DB_HOST=localhost
DB_PORT=5433
DB_NAME=docqa_llmqa
DB_USER=docqa_user
DB_PASSWORD=docqa_password

# ===========================================
# RABBITMQ CONFIGURATION
# ===========================================
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USER=docqa_user
RABBITMQ_PASSWORD=docqa_password

# ===========================================
# OLLAMA CONFIGURATION - Mistral Nemo 12B
# ===========================================
# Utiliser le LLM local (Ollama) au lieu d'OpenAI
USE_LOCAL_LLM=true

# URL du serveur Ollama
# - Windows/Mac local: http://localhost:11434
# - Dans Docker: http://host.docker.internal:11434
OLLAMA_BASE_URL=http://localhost:11434

# Modele Mistral Nemo 12B Instruct
OLLAMA_MODEL=mistral-nemo

# ===========================================
# LLM PARAMETERS
# ===========================================
# Temperature basse pour des reponses factuelles
LLM_TEMPERATURE=0.1
LLM_TOP_P=0.9
LLM_TOP_K=40
# Contexte de 8k tokens (suffisant pour RAG)
LLM_NUM_CTX=8192
LLM_REPEAT_PENALTY=1.1

# ===========================================
# RAG CONFIGURATION
# ===========================================
# Nombre de documents a recuperer
RAG_TOP_K_RESULTS=5
# Seuil de similarite minimum
RAG_SIMILARITY_THRESHOLD=0.3
# Activer le reranking pour meilleure precision
USE_RERANKING=true
# Nombre final de documents apres reranking
RERANK_TOP_K=3
# Longueur max du contexte
MAX_CONTEXT_LENGTH=6000

# ===========================================
# SERVICES EXTERNES
# ===========================================
INDEXEUR_SERVICE_URL=http://localhost:8003
AUDIT_SERVICE_URL=http://localhost:8006

# ===========================================
# OPENAI (Fallback - Optionnel)
# ===========================================
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-3.5-turbo

# ===========================================
# VECTOR STORE
# ===========================================
VECTOR_STORE_PATH=./data/vector_store
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
RAG_CHUNK_SIZE=512
RAG_CHUNK_OVERLAP=50
